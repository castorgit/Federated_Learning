{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated learning using Keras and openfl\n",
    "\n",
    "**Status:** PUBLIC Distribution <br>\n",
    "**File Name:** 02_Federated_learning_MNIST.ipynb\n",
    "\n",
    "**Author:** Jaume Manero  <br> \n",
    "**Date created:** 2023/08/23<br>\n",
    "**Last modified:** 2023/08/23<br>\n",
    "**Description:** A simple federated learning program\n",
    "\n",
    "see package requirements at the end of notebook <br>\n",
    "Based on https://github.com/securefederatedai/openfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 19:49:56.402275: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-26 19:49:56.402291: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import openfl.native as fx\n",
    "from openfl.federated import FederatedModel,FederatedDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using Tensorflow version 2.8.4\n",
      "Intel-optimizations (DNNL) enabled: False\n"
     ]
    }
   ],
   "source": [
    "def test_intel_tensorflow():\n",
    "    \"\"\"\n",
    "    Check if Intel version of TensorFlow is installed\n",
    "    \"\"\"\n",
    "    import tensorflow as tf\n",
    "\n",
    "    print(\"We are using Tensorflow version {}\".format(tf.__version__))\n",
    "\n",
    "    major_version = int(tf.__version__.split(\".\")[0])\n",
    "    if major_version >= 2:\n",
    "        from tensorflow.python.util import _pywrap_util_port\n",
    "        print(\"Intel-optimizations (DNNL) enabled:\",\n",
    "              _pywrap_util_port.IsMklEnabled())\n",
    "    else:\n",
    "        print(\"Intel-optimizations (DNNL) enabled:\")\n",
    "\n",
    "test_intel_tensorflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the required packages, the next step is setting up our openfl workspace. To do this, simply run the `fx.init()` command as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Workspace Directories\n",
      "Creating Workspace Templates\n",
      "Requirement already satisfied: tensorflow==2.8.4 in /home/manero/DL/lib/python3.8/site-packages (from -r /home/manero/.local/workspace/requirements.txt (line 1)) (2.8.4)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: gast>=0.2.1 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (1.1.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (14.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (1.22.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (56.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (1.13.3)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (2.8.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (0.27.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/manero/DL/lib/python3.8/site-packages (from tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (1.48.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/manero/DL/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (0.37.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/manero/DL/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (2.17.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/manero/DL/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/manero/DL/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/manero/DL/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/manero/DL/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/manero/DL/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/manero/DL/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (2.3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/manero/DL/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/manero/DL/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/manero/DL/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/manero/DL/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/manero/DL/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/manero/DL/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/manero/DL/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/manero/DL/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (2021.10.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/manero/DL/lib/python3.8/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/manero/DL/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/manero/DL/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.4->-r /home/manero/.local/workspace/requirements.txt (line 1)) (3.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed packages from /home/manero/.local/workspace/requirements.txt.\n",
      "\n",
      "New workspace directory structure:\n",
      "workspace\n",
      "├── plan\n",
      "│   ├── cols.yaml\n",
      "│   ├── defaults\n",
      "│   ├── plan.yaml\n",
      "│   └── data.yaml\n",
      "├── logs\n",
      "│   └── tensorboard\n",
      "│       ├── events.out.tfevents.1693066901.manero-ThinkPad-P52s\n",
      "│       ├── events.out.tfevents.1693070529.manero-ThinkPad-P52s\n",
      "│       ├── events.out.tfevents.1693066958.manero-ThinkPad-P52s\n",
      "│       ├── events.out.tfevents.1693067951.manero-ThinkPad-P52s\n",
      "│       ├── events.out.tfevents.1693066680.manero-ThinkPad-P52s\n",
      "│       ├── events.out.tfevents.1693070397.manero-ThinkPad-P52s\n",
      "│       ├── events.out.tfevents.1693071816.manero-ThinkPad-P52s\n",
      "│       ├── events.out.tfevents.1693070678.manero-ThinkPad-P52s\n",
      "│       └── events.out.tfevents.1693069175.manero-ThinkPad-P52s\n",
      "├── agg_to_col_two_signed_cert.zip\n",
      "├── requirements.txt\n",
      "├── cert\n",
      "├── agg_to_col_one_signed_cert.zip\n",
      "├── src\n",
      "│   ├── keras_cnn.py\n",
      "│   ├── mnist_utils.py\n",
      "│   ├── __init__.py\n",
      "│   └── tfmnist_inmemory.py\n",
      "├── save\n",
      "│   ├── keras_cnn_mnist_best.pbuf\n",
      "│   ├── keras_cnn_mnist_last.pbuf\n",
      "│   └── keras_cnn_mnist_init.pbuf\n",
      "├── data\n",
      "├── .workspace\n",
      "└── final_model\n",
      "    ├── variables\n",
      "    │   ├── variables.index\n",
      "    │   └── variables.data-00000-of-00001\n",
      "    ├── saved_model.pb\n",
      "    ├── keras_metadata.pb\n",
      "    └── assets\n",
      "\n",
      "10 directories, 28 files\n",
      "Setting Up Certificate Authority...\n",
      "\n",
      "1.  Create Root CA\n",
      "1.1 Create Directories\n",
      "1.2 Create Database\n",
      "1.3 Create CA Request and Certificate\n",
      "2.  Create Signing Certificate\n",
      "2.1 Create Directories\n",
      "2.2 Create Database\n",
      "2.3 Create Signing Certificate CSR\n",
      "2.4 Sign Signing Certificate CSR\n",
      "3   Create Certificate Chain\n",
      "\n",
      "Done.\n",
      "Creating AGGREGATOR certificate key pair with following settings: CN=\u001b[31mmanero-thinkpad-p52s\u001b[0m, SAN=\u001b[31mDNS:manero-thinkpad-p52s\u001b[0m\n",
      "  Writing AGGREGATOR certificate key pair to: \u001b[32m/home/manero/$Notebooks/Federated_Learning/cert/server\u001b[0m\n",
      "The CSR Hash for file \u001b[32mserver/agg_manero-thinkpad-p52s.csr\u001b[0m = \u001b[31ma97250904cbf82d3ecb9074fac8c786f4a94bd4c80fd23e6eafcacc9ab18d6e595b21bcbc83b84089fdf00534dbf5bd9\u001b[0m\n",
      " Signing AGGREGATOR certificate\n",
      "Creating COLLABORATOR certificate key pair with following settings: CN=\u001b[31mone\u001b[0m, SAN=\u001b[31mDNS:one\u001b[0m\n",
      "  Moving COLLABORATOR certificate to: \u001b[32m/home/manero/$Notebooks/Federated_Learning/cert/col_one\u001b[0m\n",
      "The CSR Hash for file \u001b[32mcol_one.csr\u001b[0m = \u001b[31m49a2a967aac1e6e92f4958d7421fa9869b8cbd550334e46df907c8b2d22594a37deb82213008b6ad39e34285b1256fb4\u001b[0m\n",
      " Signing COLLABORATOR certificate\n",
      "\n",
      "Registering \u001b[32mone\u001b[0m in \u001b[32m/home/manero/.local/workspace/plan/cols.yaml\u001b[0m\n",
      "Creating COLLABORATOR certificate key pair with following settings: CN=\u001b[31mtwo\u001b[0m, SAN=\u001b[31mDNS:two\u001b[0m\n",
      "  Moving COLLABORATOR certificate to: \u001b[32m/home/manero/$Notebooks/Federated_Learning/cert/col_two\u001b[0m\n",
      "The CSR Hash for file \u001b[32mcol_two.csr\u001b[0m = \u001b[31m3b6d75179997f1105b5a7e3d5f677a5c39e7b0025a83542ce014987bc412ed9acbca377600635c20b490d83844bb43a8\u001b[0m\n",
      " Signing COLLABORATOR certificate\n",
      "\n",
      "Registering \u001b[32mtwo\u001b[0m in \u001b[32m/home/manero/.local/workspace/plan/cols.yaml\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Setup default workspace, logging, etc.\n",
    "fx.init('keras_cnn_mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to define our dataset and model to perform federated learning on. The dataset should be composed of a numpy array <br>\n",
    "We start with a simple fully connected model that is trained on the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000 60000\n"
     ]
    }
   ],
   "source": [
    "#Import and process training, validation, and test images/labels\n",
    "\n",
    "# Set the ratio of validation imgs, can't be 0.0\n",
    "\n",
    "VALID_PERCENT = 0.3\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "split_on = int((1 - VALID_PERCENT) * len(X_train))\n",
    "print(split_on, len(X_train))\n",
    "\n",
    "train_images = X_train[0:split_on,:,:]\n",
    "train_labels = to_categorical(y_train)[0:split_on,:]\n",
    "\n",
    "valid_images = X_train[split_on:,:,:]\n",
    "valid_labels = to_categorical(y_train)[split_on:,:]\n",
    "\n",
    "test_images = X_test\n",
    "test_labels = to_categorical(y_test)\n",
    "\n",
    "def preprocess(images):\n",
    "    #Normalize\n",
    "    images = (images / 255) - 0.5\n",
    "    #Flatten\n",
    "    images = images.reshape((-1, 784))\n",
    "    return images\n",
    "\n",
    "# Preprocess the images.\n",
    "train_images = preprocess(train_images)\n",
    "valid_images = preprocess(valid_images)\n",
    "test_images  = preprocess(test_images)\n",
    "\n",
    "feature_shape = train_images.shape[1]\n",
    "classes = 10\n",
    "\n",
    "fl_data = FederatedDataSet(train_images,train_labels,valid_images,valid_labels,batch_size=32,num_classes=classes)\n",
    "\n",
    "def build_model(feature_shape,classes):\n",
    "    #Defines the MNIST model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=feature_shape, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a federated model using the build model function and dataset\n",
    "fl_model = FederatedModel(build_model,data_loader=fl_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FederatedModel` object is a wrapper around your Keras, Tensorflow or PyTorch model that makes it compatible with openfl. It provides built in federated training and validation functions that we will see used below. Using it's `setup` function, collaborator models and datasets can be automatically defined for the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "collaborator_models = fl_model.setup(num_collaborators=4)\n",
    "collaborators = {'one':collaborator_models[0],\n",
    "                 'two':collaborator_models[1],\n",
    "                'three':collaborator_models[2],\n",
    "                'four' :collaborator_models[3],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training data size: 42000\n",
      "Original validation data size: 18000\n",
      "\n",
      "Collaborator one's training data size: 10500\n",
      "Collaborator one's validation data size: 4500\n",
      "\n",
      "Collaborator two's training data size: 10500\n",
      "Collaborator two's validation data size: 4500\n",
      "\n",
      "Collaborator three's training data size: 10500\n",
      "Collaborator three's validation data size: 4500\n",
      "Collaborator four's training data size: 10500\n",
      "Collaborator four's validation data size: 4500\n"
     ]
    }
   ],
   "source": [
    "#Original MNIST dataset\n",
    "print(f'Original training data size: {len(train_images)}')\n",
    "print(f'Original validation data size: {len(valid_images)}\\n')\n",
    "\n",
    "#Collaborator one's data\n",
    "print(f'Collaborator one\\'s training data size: {len(collaborator_models[0].data_loader.X_train)}')\n",
    "print(f'Collaborator one\\'s validation data size: {len(collaborator_models[0].data_loader.X_valid)}\\n')\n",
    "\n",
    "#Collaborator two's data\n",
    "print(f'Collaborator two\\'s training data size: {len(collaborator_models[1].data_loader.X_train)}')\n",
    "print(f'Collaborator two\\'s validation data size: {len(collaborator_models[1].data_loader.X_valid)}\\n')\n",
    "\n",
    "#Collaborator three's data\n",
    "print(f'Collaborator three\\'s training data size: {len(collaborator_models[2].data_loader.X_train)}')\n",
    "print(f'Collaborator three\\'s validation data size: {len(collaborator_models[2].data_loader.X_valid)}')\n",
    "\n",
    "#Collaborator four data\n",
    "print(f'Collaborator four\\'s training data size: {len(collaborator_models[3].data_loader.X_train)}')\n",
    "print(f'Collaborator four\\'s validation data size: {len(collaborator_models[3].data_loader.X_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the current plan values by running the `fx.get_plan()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"aggregator.settings.best_state_path\": \"save/keras_cnn_mnist_best.pbuf\",\n",
      "    \"aggregator.settings.db_store_rounds\": 2,\n",
      "    \"aggregator.settings.init_state_path\": \"save/keras_cnn_mnist_init.pbuf\",\n",
      "    \"aggregator.settings.last_state_path\": \"save/keras_cnn_mnist_last.pbuf\",\n",
      "    \"aggregator.settings.rounds_to_train\": 10,\n",
      "    \"aggregator.settings.write_logs\": true,\n",
      "    \"aggregator.template\": \"openfl.component.Aggregator\",\n",
      "    \"assigner.settings.task_groups.0.name\": \"train_and_validate\",\n",
      "    \"assigner.settings.task_groups.0.percentage\": 1.0,\n",
      "    \"assigner.settings.task_groups.0.tasks.0\": \"aggregated_model_validation\",\n",
      "    \"assigner.settings.task_groups.0.tasks.1\": \"train\",\n",
      "    \"assigner.settings.task_groups.0.tasks.2\": \"locally_tuned_model_validation\",\n",
      "    \"assigner.template\": \"openfl.component.RandomGroupedAssigner\",\n",
      "    \"collaborator.settings.db_store_rounds\": 1,\n",
      "    \"collaborator.settings.delta_updates\": false,\n",
      "    \"collaborator.settings.opt_treatment\": \"RESET\",\n",
      "    \"collaborator.template\": \"openfl.component.Collaborator\",\n",
      "    \"compression_pipeline.settings\": {},\n",
      "    \"compression_pipeline.template\": \"openfl.pipelines.NoCompressionPipeline\",\n",
      "    \"data_loader.settings.batch_size\": 256,\n",
      "    \"data_loader.settings.collaborator_count\": 2,\n",
      "    \"data_loader.settings.data_group_name\": \"mnist\",\n",
      "    \"data_loader.template\": \"src.tfmnist_inmemory.TensorFlowMNISTInMemory\",\n",
      "    \"network.settings.agg_addr\": \"manero-ThinkPad-P52s\",\n",
      "    \"network.settings.agg_port\": 53350,\n",
      "    \"network.settings.cert_folder\": \"cert\",\n",
      "    \"network.settings.client_reconnect_interval\": 5,\n",
      "    \"network.settings.disable_client_auth\": false,\n",
      "    \"network.settings.hash_salt\": \"auto\",\n",
      "    \"network.settings.tls\": true,\n",
      "    \"network.template\": \"openfl.federation.Network\",\n",
      "    \"task_runner.settings\": {},\n",
      "    \"task_runner.template\": \"src.keras_cnn.KerasCNN\",\n",
      "    \"tasks.aggregated_model_validation.function\": \"validate\",\n",
      "    \"tasks.aggregated_model_validation.kwargs.apply\": \"global\",\n",
      "    \"tasks.aggregated_model_validation.kwargs.batch_size\": 32,\n",
      "    \"tasks.aggregated_model_validation.kwargs.metrics.0\": \"accuracy\",\n",
      "    \"tasks.locally_tuned_model_validation.function\": \"validate\",\n",
      "    \"tasks.locally_tuned_model_validation.kwargs.apply\": \"local\",\n",
      "    \"tasks.locally_tuned_model_validation.kwargs.batch_size\": 32,\n",
      "    \"tasks.locally_tuned_model_validation.kwargs.metrics.0\": \"accuracy\",\n",
      "    \"tasks.settings\": {},\n",
      "    \"tasks.train.function\": \"train\",\n",
      "    \"tasks.train.kwargs.batch_size\": 32,\n",
      "    \"tasks.train.kwargs.epochs\": 1,\n",
      "    \"tasks.train.kwargs.metrics.0\": \"loss\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#Get the current values of the plan. Each of these can be overridden\n",
    "print(fx.get_plan())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to run our experiment. If we want to pass in custom plan settings, we can easily do that with the `override_config` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 5s 1000us/step - loss: 0.1167 - accuracy: 0.9649\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.1307 - accuracy: 0.9590\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9556\n",
      "4500/4500 [==============================] - 5s 1ms/step - loss: 0.1058 - accuracy: 0.9684\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.1262 - accuracy: 0.9603\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9578\n",
      "4500/4500 [==============================] - 5s 1ms/step - loss: 0.1302 - accuracy: 0.9607\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.1151 - accuracy: 0.9642\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9613\n",
      "4500/4500 [==============================] - 6s 1ms/step - loss: 0.1215 - accuracy: 0.9660\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.1149 - accuracy: 0.9645\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.1668 - accuracy: 0.9556\n"
     ]
    }
   ],
   "source": [
    "#Run experiment, return trained FederatedModel\n",
    "final_fl_model = fx.run_experiment(collaborators,override_config={'aggregator.settings.rounds_to_train':1,\n",
    "                                              'tasks.aggregated_model_validation.kwargs.batch_size':16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save final model and load into keras\n",
    "final_fl_model.save_native('final_model')\n",
    "model = tf.keras.models.load_model('./final_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the final model on our test set\n",
    "score= model.evaluate(test_images,test_labels)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
